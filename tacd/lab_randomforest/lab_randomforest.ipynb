{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1b14463-2c4d-4a53-a8d1-def39d052cff",
   "metadata": {
    "tags": []
   },
   "source": [
    "# LAB 07 - Random Forest for Regression\n",
    "\n",
    "In this lab we will be extending the previous lab about Decision trees and build a Regression model using Random Forest.\n",
    "\n",
    "For simplicity, we will be using the same dataset as the previous lab (you can find it in ECLASS).\n",
    "\n",
    "**IMPORTANT:** For this lab, if you haven't finished your code from last week's lab on Decision trees, you will have the option to use the sklearn implementation for a regression tree. However, this doesn't mean that you should skip the previous lab. This is just so that you don't get behind with the content and you don't spend all your time today working on the previous lab. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b3323dc4-95cd-4564-8ccd-441019188fb9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f29dfe0-10af-4871-ab66-e7cffe0685cc",
   "metadata": {},
   "source": [
    "As mentioned before, use the Boston Housing data and prepare your train/val/test split as usual."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de6c793-4f97-49ff-a1f3-3e5ec2aa086b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Exercise 1 -- Bootstrap\n",
    "\n",
    "Also known as [bagging](https://en.wikipedia.org/wiki/Bootstrap_aggregating), this technique consists of making several samples with replacement of the original data, using each of the samples to train an estimator, and then aggregating the predictions using the average (this is also a type of model ensemble)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f7aaba32-4c00-404c-9899-7a5759059598",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap(X, num_bags=10):\n",
    "    \"\"\"\n",
    "    Given a dataset and a number of bags,\n",
    "    sample the dataset with replacement.\n",
    "    \n",
    "    This function does not return a copy\n",
    "    of the datapoints, but a list of indices\n",
    "    with compatible dimensionality\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : ndarray\n",
    "        A dataset\n",
    "    num_bags : int, default 10\n",
    "        The number of bags to create\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    list of ndarray\n",
    "        The list contains `num_bags` integer one-dimensional ndarrays.\n",
    "        Each of these contains the indices corresponding to the \n",
    "        sampled datapoints in `X`\n",
    "    \n",
    "    Notes\n",
    "    -----\n",
    "    * The number of datapoints in each bach will\n",
    "      match the number of datapoints in the given\n",
    "      dataset.\n",
    "    * The\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(0) # you can change the seed, or use 0 to replicate my results\n",
    "    # Your code here\n",
    "    \n",
    "    \n",
    "    num_samples = len(X)\n",
    "    bags = []\n",
    "    for _ in range(num_bags):\n",
    "        indices = rng.choice(num_samples, size=num_samples, replace=True)\n",
    "        bags.append(indices)\n",
    "        \n",
    "    return bags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ff32d32b-f615-43da-b70e-aa8959d01093",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([85, 63, 51, 26, 30,  4,  7,  1, 17, 81, 64, 91, 50, 60, 97, 72, 63,\n",
       "       54, 55, 93, 27, 81, 67,  0, 39, 85, 55,  3, 76, 72, 84, 17,  8, 86,\n",
       "        2, 54,  8, 29, 48, 42, 40,  2,  0, 12,  0, 67, 52, 64, 25, 61, 76,\n",
       "       38, 46, 99, 80, 98, 37, 68, 95, 65, 84, 68, 70, 38, 87, 13, 57, 72,\n",
       "       84, 52, 37, 31, 42, 48, 71, 88,  7, 93, 53, 35, 67, 57, 25, 32, 71,\n",
       "       59, 50, 33, 76, 39, 32, 89, 26, 22, 71, 62,  4,  8, 37, 83])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng = np.random.default_rng(0)\n",
    "X_small = rng.random(size=(100,2))\n",
    "bags = bootstrap(X_small)\n",
    "bags[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32b5126-5aad-4c74-a7de-ad3935acd7e8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Exercise 2 -- Aggregation\n",
    "\n",
    "The second part of bagging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "baac85e0-2a36-4ee0-92a5-e31a01a70928",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_regression(preds):\n",
    "    \"\"\"\n",
    "    Aggregate predictions by several estimators\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    preds : list of ndarray\n",
    "        Predictions from multiple estimators.\n",
    "        All ndarrays in this list should have the same\n",
    "        dimensionality.\n",
    "        \n",
    "    Return\n",
    "    ------\n",
    "    ndarray\n",
    "        The mean of the predictions\n",
    "    \"\"\"\n",
    "    # Your code here\n",
    "    return np.mean(preds, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b91f57a-6395-4285-ac01-e1099af84dde",
   "metadata": {},
   "source": [
    "## Exercise 3 -- Random Forest for regression\n",
    "\n",
    "Using the functions you implemented above, it is now time to put all of them together to train several decision trees and then ensemble them to output a single prediction. For the random forest, however, we need to select a subset of features at each split on the decision tree. \n",
    "\n",
    "For this part, you can use the sklearn implementation of Random forest for regression as your estimator for each set of features and bags. See below an example of how to do this, and always remember to check the necessary documentation when using an external function.\n",
    "\n",
    "Some parameters you will have to set are: \n",
    "* num_features: number of features per estimator\n",
    "* min_samples: min number of samples per leaf node\n",
    "* max_depth: maximum depth of the decision tree (each estimator)\n",
    "* num_estimators: number of decision trees you will create using each bag and random set of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "48ecbd9d-9628-42d4-88ee-c3c3ea408e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Validation RMSE: 1.78\n"
     ]
    }
   ],
   "source": [
    "## your code goes here:\n",
    "class RandomForest:\n",
    "    def __init__(self, num_features=4, min_samples=20, max_depth=6, num_estimators=10):\n",
    "        self.num_features = num_features\n",
    "        self.min_samples = min_samples\n",
    "        self.max_depth = max_depth\n",
    "        self.num_estimators = num_estimators\n",
    "        self.estimators = []\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        for _ in range(self.num_estimators):\n",
    "            bag_indices = bootstrap(X_train)\n",
    "        for indice in bag_indices:\n",
    "            bag_X = X_train[indice]\n",
    "            bag_y = y_train[indice]\n",
    "            rf_estimator = self._build_rf_estimator()\n",
    "            rf_estimator.fit(bag_X, bag_y)\n",
    "            self.estimators.append(rf_estimator)\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        predictions = []\n",
    "        for estimator in self.estimators:\n",
    "            pred = estimator.predict(X_test)\n",
    "            predictions.append(pred)\n",
    "        return aggregate_regression(predictions)\n",
    "\n",
    "    def _build_rf_estimator(self):\n",
    "        return DecisionTreeRegressor(\n",
    "            max_depth=self.max_depth,\n",
    "            min_samples_leaf=self.min_samples,\n",
    "            max_features=self.num_features\n",
    "        )\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(np.mean((y_true - y_pred) ** 2))\n",
    "\n",
    "# Carregando o conjunto de dados\n",
    "data = pd.read_csv(\"data/BostonHousing.txt\")\n",
    "\n",
    "# Definindo as features e o target\n",
    "X = data.drop('medv', axis=1).values\n",
    "y = data['medv'].values\n",
    "\n",
    "# Dividindo os dados em conjuntos de treino, validação e teste\n",
    "X_train, X_test_val, y_train, y_test_val = train_test_split(X, y, train_size=0.80, random_state=13)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test_val, y_test_val, test_size=0.5, random_state=13)\n",
    "\n",
    "rf = RandomForest(num_features=4, min_samples=20, max_depth=6, num_estimators=10)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_val)\n",
    "\n",
    "rmse_rf = np.sqrt(rmse(y_val, y_pred))\n",
    "\n",
    "print(f'Random Forest Validation RMSE: {rmse_rf:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d28415bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Validation RMSE: 3.87\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rfsk = RandomForestRegressor(n_estimators=10, max_depth=6, max_features = 4, min_samples_leaf= 20, random_state=0)\n",
    "\n",
    "# Treinar o modelo\n",
    "rfsk.fit(X_train, y_train)\n",
    "\n",
    "# Fazer previsões no conjunto de teste\n",
    "y_pred = rfsk.predict(X_val)\n",
    "\n",
    "# Calcular o erro quadrático médio (MSE)\n",
    "mse = rmse(y_val, y_pred)\n",
    "print(f'Random Forest Validation RMSE: {mse:.2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
