{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "425ac6e9-8919-4c06-be1c-782241f835f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6f6b7d-1fdf-43a4-bd7c-03d90114d3fb",
   "metadata": {},
   "source": [
    "# Lab 9 - Multi-layer Perceptron Forward Pass & Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99c1b83-fb9a-4321-882b-fd0c74d2ab1b",
   "metadata": {},
   "source": [
    "## Part I\n",
    "For this exercise you will implement a simple 2-layer perceptron with the forward pass and the backpropagation to learn the weights\n",
    "\n",
    "For the first part you'll build and train a 2-layer neural network that predicts the prices of houses, using the usual Boston housing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7804bef6-2bd6-4d05-bc4e-f9d8325f12ec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>b</th>\n",
       "      <th>lstat</th>\n",
       "      <th>medv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      crim    zn  indus  chas    nox     rm   age     dis  rad  tax  ptratio  \\\n",
       "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296     15.3   \n",
       "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242     17.8   \n",
       "2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242     17.8   \n",
       "3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222     18.7   \n",
       "4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222     18.7   \n",
       "\n",
       "        b  lstat  medv  \n",
       "0  396.90   4.98  24.0  \n",
       "1  396.90   9.14  21.6  \n",
       "2  392.83   4.03  34.7  \n",
       "3  394.63   2.94  33.4  \n",
       "4  396.90   5.33  36.2  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston = pd.read_csv('data/BostonHousing.txt')\n",
    "boston.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bdfc73-7702-4a3c-af9f-6fb897ec643c",
   "metadata": {
    "tags": []
   },
   "source": [
    "As usual, consider the MEDV as your target variable. \n",
    "* Split the data into training, validation and testing (70,15,15)%\n",
    "* Experiment with different number of neurons per layer for your network, using the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5df5bfc8-26c0-4d48-9c3c-05a9e404e1d4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>b</th>\n",
       "      <th>lstat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>37.66190</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.679</td>\n",
       "      <td>6.202</td>\n",
       "      <td>78.7</td>\n",
       "      <td>1.8629</td>\n",
       "      <td>24</td>\n",
       "      <td>666</td>\n",
       "      <td>20.2</td>\n",
       "      <td>18.82</td>\n",
       "      <td>14.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>0.20746</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.74</td>\n",
       "      <td>0</td>\n",
       "      <td>0.609</td>\n",
       "      <td>5.093</td>\n",
       "      <td>98.0</td>\n",
       "      <td>1.8226</td>\n",
       "      <td>4</td>\n",
       "      <td>711</td>\n",
       "      <td>20.1</td>\n",
       "      <td>318.43</td>\n",
       "      <td>29.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>9.33889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.679</td>\n",
       "      <td>6.380</td>\n",
       "      <td>95.6</td>\n",
       "      <td>1.9682</td>\n",
       "      <td>24</td>\n",
       "      <td>666</td>\n",
       "      <td>20.2</td>\n",
       "      <td>60.72</td>\n",
       "      <td>24.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>0.24103</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.38</td>\n",
       "      <td>0</td>\n",
       "      <td>0.493</td>\n",
       "      <td>6.083</td>\n",
       "      <td>43.7</td>\n",
       "      <td>5.4159</td>\n",
       "      <td>5</td>\n",
       "      <td>287</td>\n",
       "      <td>19.6</td>\n",
       "      <td>396.90</td>\n",
       "      <td>12.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.12083</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.89</td>\n",
       "      <td>0</td>\n",
       "      <td>0.445</td>\n",
       "      <td>8.069</td>\n",
       "      <td>76.0</td>\n",
       "      <td>3.4952</td>\n",
       "      <td>2</td>\n",
       "      <td>276</td>\n",
       "      <td>18.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         crim   zn  indus  chas    nox     rm   age     dis  rad  tax  \\\n",
       "427  37.66190  0.0  18.10     0  0.679  6.202  78.7  1.8629   24  666   \n",
       "490   0.20746  0.0  27.74     0  0.609  5.093  98.0  1.8226    4  711   \n",
       "429   9.33889  0.0  18.10     0  0.679  6.380  95.6  1.9682   24  666   \n",
       "327   0.24103  0.0   7.38     0  0.493  6.083  43.7  5.4159    5  287   \n",
       "97    0.12083  0.0   2.89     0  0.445  8.069  76.0  3.4952    2  276   \n",
       "\n",
       "     ptratio       b  lstat  \n",
       "427     20.2   18.82  14.52  \n",
       "490     20.1  318.43  29.68  \n",
       "429     20.2   60.72  24.08  \n",
       "327     19.6  396.90  12.79  \n",
       "97      18.0  396.90   4.21  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code goes here\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = boston.drop('medv', axis=1)\n",
    "y = boston['medv']\n",
    "\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.50, random_state=42)\n",
    "\n",
    "X_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dcc26211-91c1-47f9-8779-eb723b0c209e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here\n",
    "class Layer:\n",
    "    def __init__(self):\n",
    "        self.input = None\n",
    "        self.output = None\n",
    "\n",
    "    # computes the output Y of a layer for a given input X\n",
    "    def forward_propagation(self, input):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    # computes dE/dX for a given dE/dY (and update parameters if any)\n",
    "    def backward_propagation(self, output_error, learning_rate):\n",
    "        raise NotImplementedError\n",
    "\n",
    "# inherit from base class Layer\n",
    "class FCLayer(Layer):\n",
    "    def __init__(self, input_size, output_size, activation, activation_prime):\n",
    "        self.weights = np.random.rand(input_size, output_size) * 0.01\n",
    "        self.bias = np.random.rand(1, output_size) * 0.01\n",
    "        self.activation = activation\n",
    "        self.activation_prime = activation_prime\n",
    "\n",
    "    # returns output for a given input\n",
    "    def forward_propagation(self, input_data):\n",
    "        self.input = input_data.reshape(1, -1)\n",
    "        self.output = self.activation(np.dot(self.input, self.weights) + self.bias)\n",
    "        return self.output\n",
    "\n",
    "    # computes dE/dW, dE/dB for a given output_error=dE/dY. Returns input_error=dE/dX.\n",
    "    def backward_propagation(self, grad_output, learning_rate):\n",
    "        grad_input = np.dot(grad_output, self.weights.T)\n",
    "        grad_weights = np.dot(self.input.T, grad_output)\n",
    "        grad_weights = self.activation_prime(grad_weights) * grad_output\n",
    "\n",
    "        # update parameters\n",
    "        # print(\"Erro da camada: \", grad_weights, \"\\n\")\n",
    "        self.weights -= learning_rate * grad_weights\n",
    "        self.bias -= learning_rate * grad_output\n",
    "        return grad_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "38e94848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here\n",
    "class Network:\n",
    "    def __init__(self):\n",
    "        self.layers = []\n",
    "        self.loss = None\n",
    "        self.loss_prime = None\n",
    "\n",
    "    # add layer to network\n",
    "    def add(self, layer):\n",
    "        self.layers.append(layer)\n",
    "\n",
    "    # set loss to use\n",
    "    def use(self, loss, loss_prime):\n",
    "        self.loss = loss\n",
    "        self.loss_prime = loss_prime\n",
    "\n",
    "    # predict output for given input\n",
    "    def predict(self, input_data):\n",
    "        # sample dimension first\n",
    "        result = []\n",
    "        \n",
    "        if isinstance(input_data, pd.DataFrame): input_data = input_data.values\n",
    "\n",
    "        # run network over all samples\n",
    "        for output in input_data:\n",
    "            # forward propagation\n",
    "            for layer in self.layers:\n",
    "                output = layer.forward_propagation(output)\n",
    "            result.append(output)\n",
    "\n",
    "        return result\n",
    "\n",
    "    # train the network\n",
    "    def fit(self, X_train, y_train, epochs, learning_rate):\n",
    "        # sample dimension first\n",
    "        samples = len(X_train)\n",
    "        \n",
    "        if isinstance(X_train, pd.DataFrame): X_train = X_train.values\n",
    "\n",
    "        # training loop\n",
    "        for i in range(epochs):\n",
    "            err = 0\n",
    "            for output, y_real in zip(X_train, y_train):\n",
    "                \n",
    "                if not isinstance(y_real, np.ndarray): y_real = np.array(y_real)\n",
    "                \n",
    "                # forward propagation\n",
    "                for layer in self.layers:\n",
    "                    output = layer.forward_propagation(output)\n",
    "\n",
    "                # compute loss (for display purpose only)\n",
    "                err += self.loss(y_real, output)\n",
    "\n",
    "                # backward propagation\n",
    "                error = self.loss_prime(y_real, output)\n",
    "                for layer in reversed(self.layers):\n",
    "                    error = layer.backward_propagation(error, learning_rate)\n",
    "\n",
    "            # calculate average error on all samples\n",
    "            err /= samples\n",
    "            print(\"epoch %d/%d   error=%f\" % (i+1, epochs, err))\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e5b1b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(y_true, y_pred):\n",
    "    return np.mean(np.power(y_true-y_pred, 2))\n",
    "\n",
    "def mse_prime(y_true, y_pred):\n",
    "    return 2*(y_pred-y_true)/y_true.size\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_prime(x):\n",
    "    return sigmoid(x) * (1 - sigmoid(x))\n",
    "\n",
    "def identity(x):\n",
    "    return x\n",
    "\n",
    "def identity_prime(x):\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f5486807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/10   error=60176011353.643959\n",
      "epoch 2/10   error=1006.197168\n",
      "epoch 3/10   error=1001.140626\n",
      "epoch 4/10   error=1001.140628\n",
      "epoch 5/10   error=1001.140628\n",
      "epoch 6/10   error=1001.140628\n",
      "epoch 7/10   error=1001.140628\n",
      "epoch 8/10   error=1001.140628\n",
      "epoch 9/10   error=1001.140628\n",
      "epoch 10/10   error=1001.140628\n",
      "[array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]]), array([[42.22738236]])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32518/2731484771.py:8: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n"
     ]
    }
   ],
   "source": [
    "net = Network()\n",
    "net.add(FCLayer(len(X_train.iloc[0]), 20, sigmoid, sigmoid_prime))\n",
    "net.add(FCLayer(20, 1, identity, identity_prime))\n",
    "\n",
    "# train\n",
    "net.use(mse, mse_prime)\n",
    "net.fit(X_train, y_train, epochs=10, learning_rate=0.12)\n",
    "\n",
    "# test\n",
    "out = net.predict(X_train)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6650ab-79e5-4636-a4c9-84b977c48541",
   "metadata": {},
   "source": [
    "## Part II \n",
    "\n",
    "For this exercise you will build and train a 2-layer neural network that predicts the exact digit from a hand-written image, using the MNIST dataset. \n",
    "For this exercise, add weight decay to your network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3bfe2473-16e8-4dce-9e5b-7d5ce1154200",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f8f04ee-c8e6-4531-9ad4-b0e530e1f92d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "digits = load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c49e3cd-e16a-4847-ac73-b9628f3f159a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = digits.data\n",
    "y = digits.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "172b3419-d470-433f-87f9-4df67e4761e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdaf177-1cda-4c04-8d12-090678310602",
   "metadata": {},
   "source": [
    "Again, you will split the data into training, validation and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8519363c-f7e0-43a8-ba4e-a33ab9d5b96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "015f701c-f816-4208-8cdc-4ba32f03f08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here:\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
